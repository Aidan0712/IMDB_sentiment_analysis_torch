[0m

[ERRORS]
2025-10-26 20:01:13,965: INFO: running D:\2025Autumn\Scientific Research Training\Task3\imdb_sentiment_analysis_torch\imdb_distilbert_trainer.py
C:\Users\Clumsy\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py:143: UserWarning:

`huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\Users\Clumsy\.cache\huggingface\hub\models--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.
To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development


Map:   0%|          | 0/20000 [00:00<?, ? examples/s]
Map:   5%|â–Œ         | 1000/20000 [00:00<00:04, 3802.45 examples/s]
Map:  10%|â–ˆ         | 2000/20000 [00:00<00:03, 5322.25 examples/s]
Map:  15%|â–ˆâ–Œ        | 3000/20000 [00:00<00:02, 5715.84 examples/s]
Map:  20%|â–ˆâ–ˆ        | 4000/20000 [00:00<00:02, 6328.19 examples/s]
Map:  25%|â–ˆâ–ˆâ–Œ       | 5000/20000 [00:00<00:02, 6451.22 examples/s]
Map:  30%|â–ˆâ–ˆâ–ˆ       | 6000/20000 [00:01<00:02, 6121.17 examples/s]
Map:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7000/20000 [00:01<00:02, 6190.78 examples/s]
Map:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8000/20000 [00:01<00:01, 6224.10 examples/s]
Map:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9000/20000 [00:01<00:01, 5848.71 examples/s]
Map:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10000/20000 [00:01<00:01, 5852.44 examples/s]
Map:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11000/20000 [00:01<00:01, 5916.44 examples/s]
Map:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12000/20000 [00:02<00:01, 5941.05 examples/s]
Map:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13000/20000 [00:02<00:01, 5901.16 examples/s]
Map:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14000/20000 [00:02<00:01, 5774.25 examples/s]
Map:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15000/20000 [00:02<00:00, 5324.72 examples/s]
Map:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16000/20000 [00:02<00:00, 5558.77 examples/s]
Map:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17000/20000 [00:02<00:00, 5578.55 examples/s]
Map:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18000/20000 [00:03<00:00, 5715.04 examples/s]
Map:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19000/20000 [00:03<00:00, 5694.99 examples/s]
Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [00:03<00:00, 6056.09 examples/s]
Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [00:03<00:00, 5798.63 examples/s]

Map:   0%|          | 0/5000 [00:00<?, ? examples/s]
Map:  20%|â–ˆâ–ˆ        | 1000/5000 [00:00<00:00, 6655.00 examples/s]
Map:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2000/5000 [00:00<00:00, 6157.46 examples/s]
Map:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3000/5000 [00:00<00:00, 6224.94 examples/s]
Map:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4000/5000 [00:00<00:00, 6286.89 examples/s]
Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:00<00:00, 6075.85 examples/s]
Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:00<00:00, 6080.67 examples/s]

Map:   0%|          | 0/25000 [00:00<?, ? examples/s]
Map:   4%|â–         | 1000/25000 [00:00<00:03, 7243.79 examples/s]
Map:   8%|â–Š         | 2000/25000 [00:00<00:03, 6939.38 examples/s]
Map:  12%|â–ˆâ–        | 3000/25000 [00:00<00:03, 6872.07 examples/s]
Map:  16%|â–ˆâ–Œ        | 4000/25000 [00:00<00:03, 6627.72 examples/s]
Map:  20%|â–ˆâ–ˆ        | 5000/25000 [00:00<00:02, 6735.27 examples/s]
Map:  24%|â–ˆâ–ˆâ–       | 6000/25000 [00:01<00:03, 4862.64 examples/s]
Map:  28%|â–ˆâ–ˆâ–Š       | 7000/25000 [00:01<00:03, 5266.00 examples/s]
Map:  32%|â–ˆâ–ˆâ–ˆâ–      | 8000/25000 [00:01<00:03, 5617.73 examples/s]
Map:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9000/25000 [00:01<00:02, 5719.37 examples/s]
Map:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10000/25000 [00:01<00:02, 5917.67 examples/s]
Map:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11000/25000 [00:01<00:02, 5757.64 examples/s]
Map:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12000/25000 [00:02<00:02, 5751.98 examples/s]
Map:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13000/25000 [00:02<00:02, 5606.52 examples/s]
Map:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14000/25000 [00:02<00:01, 5726.74 examples/s]
Map:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15000/25000 [00:02<00:01, 5944.23 examples/s]
Map:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16000/25000 [00:02<00:01, 6020.50 examples/s]
Map:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17000/25000 [00:02<00:01, 5929.19 examples/s]
Map:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18000/25000 [00:03<00:01, 5999.91 examples/s]
Map:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19000/25000 [00:03<00:00, 6213.30 examples/s]
Map:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20000/25000 [00:03<00:00, 6160.25 examples/s]
Map:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21000/25000 [00:03<00:00, 5925.01 examples/s]
Map:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22000/25000 [00:03<00:00, 5968.72 examples/s]
Map:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23000/25000 [00:03<00:00, 5980.53 examples/s]
Map:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24000/25000 [00:04<00:00, 5906.37 examples/s]
Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25000/25000 [00:04<00:00, 5995.03 examples/s]
Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25000/25000 [00:04<00:00, 5920.74 examples/s]
Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
2025-10-26 20:01:30,612: WARNING: Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Traceback (most recent call last):
  File "D:\2025Autumn\Scientific Research Training\Task3\imdb_sentiment_analysis_torch\imdb_distilbert_trainer.py", line 48, in <module>
    metric = datasets.load_metric("accuracy")
             ^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'datasets' has no attribute 'load_metric'
