tensor([[ 3,  4,  2,  ...,  0,  0,  0],
        [ 3,  4,  2,  ...,  0,  0,  0],
        [ 3,  4, 15,  ...,  0,  0,  0],
        ...,
        [12, 13, 15,  ...,  0,  0,  0],
        [ 1,  4,  6,  ...,  0,  0,  0],
        [25, 19, 12,  ...,  0,  0,  0]]) tensor([ 617, 1839,  630, 2244, 1514,  721,  805,  871,  990, 3245,  923,  646,
         893, 1764, 1431, 1479,  542, 1398, 1556,  646,  810, 1393,  312,  797,
        1040, 2324,  668, 1454, 2919,  161,  911,  846, 1443, 4515,  370,  778,
         864, 1615, 1107, 2952, 1090, 1698, 5552,  559, 1082,  988, 1094,  735,
         777,  394,  626,  836, 3472,  720, 1416,  562, 4531,  500,  962, 1624,
        2509,  766, 1385, 1635]) tensor([0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,
        1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1,
        0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1])
[0m

[ERRORS]
2025-10-26 22:46:12,731: INFO: running D:\2025Autumn\Scientific Research Training\Task3\imdb_sentiment_analysis_torch\imdb_transformer.py
D:\2025Autumn\Scientific Research Training\Task3\imdb_sentiment_analysis_torch\imdb_transformer.py:46: MarkupResemblesLocatorWarning:

The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.

C:\Users\Clumsy\AppData\Roaming\Python\Python312\site-packages\torch\nn\modules\transformer.py:392: UserWarning:

enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)


Epoch 0:   0%|          | 0/313 [00:00<?, ?it/s]
Epoch 0:   0%|          | 0/313 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "D:\2025Autumn\Scientific Research Training\Task3\imdb_sentiment_analysis_torch\imdb_transformer.py", line 227, in <module>
    score = net(feature, lengths)
            ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Clumsy\AppData\Roaming\Python\Python312\site-packages\torch\nn\modules\module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Clumsy\AppData\Roaming\Python\Python312\site-packages\torch\nn\modules\module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\2025Autumn\Scientific Research Training\Task3\imdb_sentiment_analysis_torch\imdb_transformer.py", line 145, in forward
    hidden_states = self.position_embedding(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Clumsy\AppData\Roaming\Python\Python312\site-packages\torch\nn\modules\module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Clumsy\AppData\Roaming\Python\Python312\site-packages\torch\nn\modules\module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\2025Autumn\Scientific Research Training\Task3\imdb_sentiment_analysis_torch\imdb_transformer.py", line 124, in forward
    x = x + self.pe[:x.size(0), :]
        ~~^~~~~~~~~~~~~~~~~~~~~~~~
RuntimeError: The size of tensor a (5552) must match the size of tensor b (128) at non-singleton dimension 0
